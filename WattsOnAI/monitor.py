import sys
import os

# è¿™é‡Œçš„è·¯å¾„éœ€è¦æ ¹æ®å®é™…æƒ…å†µè¿›è¡Œè°ƒæ•´
# Fix the path append - get the directory where this file is located
# sys.path.append('__file__' + '/..')
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__))) # Fix

import time
from datetime import datetime
import threading

from get_carbon_density import get_current_carbon_intensity, compute_carbon_emission
from metrics_calculate import calculate_metrics, calculate_metrics_from_mysql
from metrics_collect import parallel_collect_metrics
from save import save_to_csv, save_to_mysql
import state
from resources_consumption_record import get_average_time, get_max_time, monitor_resources
import math

# --- æ ¼å¼åŒ–å¸¸é‡ ---
# æŒ‡æ ‡æ ‡ç­¾çš„å®½åº¦ï¼ˆä¾‹å¦‚ï¼š"cpu_usage", "power.draw [W]"ï¼‰
LABEL_WIDTH = 30
# æ¯ä¸ªç»Ÿè®¡å€¼çš„å®½åº¦ï¼ˆå¹³å‡å€¼ã€æœ€å¤§å€¼ã€æœ€å°å€¼ã€ä¼—æ•°ï¼‰
VALUE_WIDTH = 20
# åˆ†éš”çº¿é•¿åº¦
SEPARATOR_LEN = 146

def _safe_float(value, default=None):
    """å®‰å…¨åœ°å°†å€¼è½¬æ¢ä¸ºæµ®ç‚¹æ•°ï¼Œå¤„ç†'N/A'æˆ–é”™è¯¯æƒ…å†µ"""
    if isinstance(value, (int, float)) and not math.isnan(value):
        return float(value)
    try:
        return float(value)
    except (ValueError, TypeError):
        return default

def _format_value(value, width=VALUE_WIDTH, precision=2):
    """å°†å•ä¸ªå€¼ï¼ˆæ•°å­—æˆ–åƒ'N/A'è¿™æ ·çš„å­—ç¬¦ä¸²ï¼‰æ ¼å¼åŒ–ä¸ºå›ºå®šå®½åº¦"""
    num_value = _safe_float(value)
    if num_value is not None:
        # ä½¿ç”¨æŒ‡å®šç²¾åº¦æ ¼å¼åŒ–æ•°å­—
        formatted_val = f"{num_value:.{precision}f}"
    else:
        # å¤„ç†'N/A'æˆ–å…¶ä»–éæ•°å­—å­—ç¬¦ä¸²
        formatted_val = str(value)
    # å°†æ ¼å¼åŒ–åçš„å€¼å¡«å……åˆ°æ‰€éœ€å®½åº¦
    return f"{formatted_val:<{width}}"

def _format_stat_dict(stat_dict: dict | str | int | float, key_name: str = "", total_time: str | float = "N/A") -> str:
    """
    å°†ç»Ÿè®¡ä¿¡æ¯å­—å…¸æˆ–å•ä¸ªå€¼æ ¼å¼åŒ–ä¸ºå…·æœ‰å¯¹é½åˆ—çš„å¯è¯»å­—ç¬¦ä¸²ã€‚
    """

    # å¤„ç†ç®€å•çš„éå­—å…¸å€¼ï¼ˆå¦‚ PCIe é“¾æ¥ä¿¡æ¯ï¼‰
    if not isinstance(stat_dict, dict):
        # ä»…è¿”å›å€¼ï¼Œä¸ºä¿æŒä¸€è‡´æ€§ç¨ä½œå¡«å……
        return str(stat_dict) # è¿™é‡Œä¸éœ€è¦å¤æ‚çš„å¯¹é½

    # æ ¼å¼åŒ–æ ‡å‡†ç»Ÿè®¡å­—å…¸ï¼ˆå¹³å‡å€¼ã€æœ€å¤§å€¼ã€æœ€å°å€¼ã€ä¼—æ•°ï¼‰
    mean = stat_dict.get('mean', 'N/A')
    max_val = stat_dict.get('max', 'N/A')
    min_val = stat_dict.get('min', 'N/A')
    mode_val = stat_dict.get('mode', 'N/A')

    # å¦‚æœæ‰€æœ‰ç»Ÿè®¡å€¼éƒ½æ˜¯'N/A'ï¼Œåˆ™è¿”å›ç®€å•çš„'N/A'
    if all(v == 'N/A' for v in [mean, max_val, min_val, mode_val]):
        return "N/A"

    # ä½¿ç”¨å›ºå®šå®½åº¦æ ¼å¼åŒ–æ¯ä¸ªéƒ¨åˆ†ä»¥å®ç°å¯¹é½
    mean_str = f"Avg: {_format_value(mean)}"
    max_str = f"Max: {_format_value(max_val)}"
    min_str = f"Min: {_format_value(min_val)}"
    mode_str = f"Mode: {_format_value(mode_val)}"

    # ç»„åˆå¯¹é½åçš„å„ä¸ªéƒ¨åˆ†
    return f"{mean_str} {max_str} {min_str} {mode_str}"


# æ‰“å°æ ¼å¼åŒ–åçš„æ€§èƒ½æŒ‡æ ‡
def print_formatted_metrics(metrics: dict[str, any], task_name: str):
    """
    ä»¥ç»“æ„åŒ–ã€å¯¹é½ä¸”æ›´ç¾è§‚çš„æ–¹å¼æ‰“å°è®¡ç®—å¾—åˆ°çš„æ€§èƒ½æŒ‡æ ‡ã€‚
    å‚æ•°:
        metrics (Dict[str, Any]): ç”± calculate_metrics è¿”å›çš„æŒ‡æ ‡å­—å…¸ã€‚
        task_name (str): è¢«ç›‘æ§çš„ä»»åŠ¡åç§°ã€‚
    """
    if not metrics:
        print("\n[Error] æŒ‡æ ‡æ•°æ®ä¸ºç©ºæˆ–æ— æ•ˆï¼Œæ— æ³•æ‰“å°æ ¼å¼åŒ–ç»“æœã€‚\n")
        return {}

    # å®‰å…¨è·å–å„éƒ¨åˆ†æŒ‡æ ‡
    cpu_dram_stats = metrics.get('cpu_dram_stats', {})
    gpu_stats = metrics.get('gpu_stats', {})
    total_time = metrics.get('total_time', 'N/A')
    energy_consumption = metrics.get('energy_consumption', {})

    # æ‰“å°é¡µçœ‰
    print("\n" + "=" * SEPARATOR_LEN)
    # print(f"ğŸ“Š {'ä»»åŠ¡ï¼š' + repr(task_name) + ' çš„æ€§èƒ½æŒ‡æ ‡æ±‡æ€»':^{SEPARATOR_LEN-16}} ğŸ“Š") # å±…ä¸­æ ‡é¢˜
    # å†™æˆè‹±æ–‡
    print(f"ğŸ“Š {'Task: ' + repr(task_name) + ' Performance Metrics Summary':^{SEPARATOR_LEN-8}} ğŸ“Š") # å±…ä¸­æ ‡é¢˜
    print("=" * SEPARATOR_LEN)

    # æ‰“å°æ€»è§ˆéƒ¨åˆ†
    # print("\n[ ğŸ•’ æ€»è§ˆï¼šæ€»è€—æ—¶ä¸èƒ½è€— ]")
    # å†™æˆè‹±æ–‡
    print("\n[ ğŸ•’ Overview: Total Time and Energy Consumption ]")
    # total_time_float = _safe_float(total_time)
    # total_time_str = f"{total_time_float:.2f} S" if total_time_float is not None else "N/A"
    # print(f"  {'ä»»åŠ¡æ€»è€—æ—¶':<{LABEL_WIDTH}}: {total_time}")
    # å†™æˆè‹±æ–‡
    # æŠŠtotal_timeçš„ç§’è½¬æ¢ä¸ºsecond
    print(f"  {'Total Time':<{LABEL_WIDTH}}: {total_time.replace('ç§’', 'S')}")
    print("-" * (SEPARATOR_LEN // 2)) # è¾ƒçŸ­çš„åˆ†éš”çº¿

    # æ ¼å¼åŒ–èƒ½è€—å€¼
    # print(f"  {'CPU èƒ½è€—':<{LABEL_WIDTH}}: {_format_value(energy_consumption.get('cpu_energy'), precision=3)} Joules")
    # print(f"  {'DRAM èƒ½è€—':<{LABEL_WIDTH}}: {_format_value(energy_consumption.get('dram_energy'), precision=3)} Joules")
    # # å†™æˆè‹±æ–‡
    print(f"  {'CPU Energy':<{LABEL_WIDTH}}: {_format_value(energy_consumption.get('cpu_energy'), precision=3)}")
    print(f"  {'DRAM Energy':<{LABEL_WIDTH}}: {_format_value(energy_consumption.get('dram_energy'), precision=3)}")


    gpu_energy = energy_consumption.get('gpu_energy', {})
    if gpu_energy:
        # æŒ‰GPUç´¢å¼•æ•°å€¼æ’åºåæ‰“å°
        for gpu_idx in sorted(gpu_energy.keys(), key=lambda x: int(x) if str(x).isdigit() else float('inf')):
            energy = gpu_energy[gpu_idx]
            # print(f"  {f'GPU {gpu_idx} èƒ½è€—':<{LABEL_WIDTH}}: {_format_value(energy, precision=3)} Joules")
            # å†™æˆè‹±æ–‡
            print(f"  {f'GPU {gpu_idx} Energy':<{LABEL_WIDTH}}: {_format_value(energy, precision=3)}")

    # print(f"  {'æ€»èƒ½è€—':<{LABEL_WIDTH-1}}: {_format_value(energy_consumption.get('total_energy'), precision=3)} Joules")
    # å†™æˆè‹±æ–‡
    print(f"  {'Total Energy':<{LABEL_WIDTH}}: {_format_value(energy_consumption.get('total_energy'), precision=3)}")
    
    # For performance metrics
    lbs, kg = None, None
    result = {}  # Fresh result dict for each model
        
    if state._position_use == 1: 
        result = get_current_carbon_intensity(
            username="rkv_exploring", 
            password="viqgup-huswas-6keCxy", 
            # latitude=state._latitude, 
            # longitude=state._longitude
            cloud_region = state._cloud_region
            )
        
        lbs, kg = compute_carbon_emission(float(energy_consumption.get('total_energy', '0 J').replace(" J", "")), result['value'])
        print(f"  {'Carbon Emissions':<{LABEL_WIDTH}}: {kg} kg CO2eq")

    # æ‰“å°CPU/DRAMç»Ÿè®¡ä¿¡æ¯
    # print("\n[ ğŸ–¥ï¸ CPU å’Œ DRAM ç»Ÿè®¡ä¿¡æ¯ ]")
    # å†™æˆè‹±æ–‡
    print("\n[ ğŸ–¥ï¸ CPU and DRAM Statistics ]")
    print("-" * (SEPARATOR_LEN // 2))
    if cpu_dram_stats:
        # æŒ‡å®šCPU/DRAMæŒ‡æ ‡çš„æ˜¾ç¤ºé¡ºåº
        cpu_dram_order = ['cpu_usage', 'cpu_power', 'dram_usage', 'dram_power'] # ç¤ºä¾‹åç§°ï¼Œæ ¹æ®éœ€è¦è°ƒæ•´
        # æ·»åŠ æœªåœ¨é¦–é€‰é¡ºåºä¸­çš„å…¶ä»–CPU/DRAMæŒ‡æ ‡
        other_keys = [k for k in cpu_dram_stats if k not in cpu_dram_order]
        
        # é¦–å…ˆæŒ‰ç…§é¦–é€‰é¡ºåºæ‰“å°
        printed_any = False
        for metric in cpu_dram_order:
            if metric in cpu_dram_stats:
                stats = cpu_dram_stats[metric]
                formatted_stats = _format_stat_dict(stats, key_name=metric, total_time=total_time)
                print(f"  {metric:<{LABEL_WIDTH}}: {formatted_stats}")
                printed_any = True
        
        # æ‰“å°å‰©ä½™æŒ‡æ ‡
        for metric in other_keys:
             stats = cpu_dram_stats[metric]
             formatted_stats = _format_stat_dict(stats, key_name=metric, total_time=total_time)
             print(f"  {metric:<{LABEL_WIDTH}}: {formatted_stats}")
             printed_any = True

        if not printed_any:
             print("  (æ— æœ‰æ•ˆçš„ CPU/DRAM ç»Ÿè®¡æ•°æ®)")

    else:
        print("  (æ—  CPU/DRAM ç»Ÿè®¡ä¿¡æ¯)")

    # æ‰“å°GPUç»Ÿè®¡ä¿¡æ¯
    # print("\n[ ğŸš€ GPU è¯¦ç»†ç»Ÿè®¡ä¿¡æ¯ ]")
    # å†™æˆè‹±æ–‡
    print("\n[ ğŸš€ GPU Detailed Statistics ]")
    if not gpu_stats:
        print("-" * (SEPARATOR_LEN // 2))
        print("  (æ—  GPU ç»Ÿè®¡ä¿¡æ¯)")
    else:
        # å®šä¹‰GPUæŒ‡æ ‡åˆ†ç±»ï¼ˆæ ¹æ®å®é™…æ•°æ®è°ƒæ•´é”®å€¼ï¼‰
        # è¿™é‡Œä½¿ç”¨æ›´é€šç”¨çš„é”®å€¼ï¼Œéœ€è¦æ ¹æ®calculate_metricsçš„å®é™…é”®å€¼æ›¿æ¢
        gpu_sections = {
            "Energy Section": [
                'power.draw [W]',
                'temperature.gpu',
            ],
            "Compute Section": [
                'utilization.gpu [%]',
                'clocks.current.graphics [MHz]',
                'clocks.current.sm [MHz]',
                'sm_active',
                'sm_occupancy',
                'tensor_active',
                'fp64_active',
                'fp32_active',
                'fp16_active',
            ],
            "Memory Section": [
                'utilization.memory [%]',
                'temperature.memory',
                'clocks.current.memory [MHz]',
                'usage.memory [%]',
                'dram_active',
            ],
            "Communication Section": [
                'pcie.link.gen.current',
                'pcie.link.width.current',
                'pcie_tx_bytes',
                'pcie_rx_bytes',
                'nvlink_tx_bytes',
                'nvlink_rx_bytes',
            ]
        }

        # å¯¹GPUç´¢å¼•è¿›è¡Œæ•°å€¼æ’åºä»¥ä¿æŒè¾“å‡ºé¡ºåºä¸€è‡´
        sorted_gpu_indices = sorted(gpu_stats.keys(), key=lambda x: int(x) if str(x).isdigit() else float('inf'))

        for i, gpu_idx in enumerate(sorted_gpu_indices):
            gpu_data = gpu_stats[gpu_idx]
            gpu_name = gpu_data.get('name', 'æœªçŸ¥åç§°')

            # ä¸ºæ¯ä¸ªGPUæ‰“å°æ¸…æ™°çš„åˆ†éš”ç¬¦å’Œæ ‡é¢˜
            if i > 0: # ä»ç¬¬äºŒä¸ªGPUå¼€å§‹æ·»åŠ é¢å¤–ç©ºè¡Œ
                print("\n" + "~" * (SEPARATOR_LEN // 2) + "\n") # ä½¿ç”¨ä¸åŒçš„åˆ†éš”ç¬¦
            else:
                print("-" * (SEPARATOR_LEN // 2)) # åˆå§‹åˆ†éš”ç¬¦

            print(f"  --- GPU {gpu_idx} ({gpu_name}) ---")

            # éå†å®šä¹‰çš„åˆ†ç±»
            for section_name, metric_keys in gpu_sections.items():
                section_has_data = False
                section_output = [] # å­˜å‚¨è¯¥åˆ†ç±»çš„è¾“å‡ºè¡Œ

                for key in metric_keys:
                    if key in gpu_data:
                        stats_or_value = gpu_data[key]
                        # ä½¿ç”¨æ”¹è¿›çš„_format_stat_dictå¤„ç†å¯¹é½å’Œå¸¦å®½
                        formatted_value = _format_stat_dict(stats_or_value, key_name=key, total_time=total_time)

                        # å°†æ ¼å¼åŒ–çš„è¡Œæ·»åŠ åˆ°åˆ†ç±»è¾“å‡ºä¸­
                        section_output.append(f"    {key:<{LABEL_WIDTH}}: {formatted_value}")
                        section_has_data = True

                # ä»…åœ¨æœ‰æ•°æ®æ—¶æ‰“å°åˆ†ç±»æ ‡é¢˜å’Œæ•°æ®
                if section_has_data:
                    print(f"\n    [{section_name}]") # åœ¨åˆ†ç±»æ ‡é¢˜å‰æ·»åŠ ç©ºè¡Œ
                    for line in section_output:
                        print(line)

    # æ‰“å°é¡µè„š
    print("\n" + "=" * SEPARATOR_LEN)
    # print("ğŸ“Š æŒ‡æ ‡æ±‡æ€»ç»“æŸ ğŸ“Š".center(SEPARATOR_LEN))
    # å†™æˆè‹±æ–‡
    print("ğŸ“Š Summary of Metrics Collection Ended ğŸ“Š".center(SEPARATOR_LEN))
    print("=" * SEPARATOR_LEN + "\n")
    
    # Helper function to safely extract numeric values
    def safe_extract_numeric(value):
        if isinstance(value, (int, float)):
            return value
        if isinstance(value, str):
            # Remove common units and convert to float
            cleaned = value.replace(' J', '').replace(' W', '').replace(' %', '').replace(' MHz', '').replace(' Â°C', '')
            try:
                return float(cleaned)
            except (ValueError, TypeError):
                return None
        return None
    
    # Helper function to extract statistics from stat dict
    def extract_stat_dict(stat_dict):
        if not isinstance(stat_dict, dict):
            return {"value": safe_extract_numeric(stat_dict)}
        
        return {
            "mean": safe_extract_numeric(stat_dict.get('mean')),
            "max": safe_extract_numeric(stat_dict.get('max')),
            "min": safe_extract_numeric(stat_dict.get('min')),
            "mode": safe_extract_numeric(stat_dict.get('mode'))
        }
    
    # Build comprehensive performance JSON
    performance_json = {
        "metadata": {
            "task_name": task_name,
            "generated_at": datetime.now().isoformat(),
            "total_execution_time": total_time,
            "csv_file_path": getattr(state, '_csv_file_path', ''),
            "sample_count": getattr(state, '_inserted_count', 0),
            "sampling_interval": getattr(state, '_sampling_interval', 1.0),
            "position_used": state._position_use == 1,
            "cloud_region": result.get("cloud_region" ,"Unknown_Region")  
        },
        "energy_metrics": {
            "cpu_energy_joules": safe_extract_numeric(energy_consumption.get('cpu_energy', 0)),
            "dram_energy_joules": safe_extract_numeric(energy_consumption.get('dram_energy', 0)),
            "total_energy_joules": safe_extract_numeric(energy_consumption.get('total_energy', 0)),
            "carbon_emissions_kg": kg,
            "carbon_emissions_lbs": lbs,
            "gpu_energy_joules": {}
        },
        "cpu_dram_metrics": {},
        "gpu_metrics": {}
    }
    
    # Populate GPU energy in energy_metrics
    gpu_energy = energy_consumption.get('gpu_energy', {})
    for gpu_idx, energy in gpu_energy.items():
        performance_json["energy_metrics"]["gpu_energy_joules"][str(gpu_idx)] = safe_extract_numeric(energy)
    
    # Populate CPU/DRAM metrics
    for metric_name, metric_data in cpu_dram_stats.items():
        performance_json["cpu_dram_metrics"][metric_name] = extract_stat_dict(metric_data)
    
    # Populate GPU metrics with detailed categorization
    gpu_sections = {
        "energy": ['power.draw [W]', 'temperature.gpu'],
        "compute": [
            'utilization.gpu [%]', 'clocks.current.graphics [MHz]', 'clocks.current.sm [MHz]',
            'sm_active', 'sm_occupancy', 'tensor_active', 'fp64_active', 'fp32_active', 'fp16_active'
        ],
        "memory": [
            'utilization.memory [%]', 'temperature.memory', 'clocks.current.memory [MHz]',
            'usage.memory [%]', 'dram_active'
        ],
        "communication": [
            'pcie.link.gen.current', 'pcie.link.width.current', 'pcie_tx_bytes', 
            'pcie_rx_bytes', 'nvlink_tx_bytes', 'nvlink_rx_bytes'
        ]
    }
    
    # Process each GPU
    for gpu_idx, gpu_data in gpu_stats.items():
        gpu_id = str(gpu_idx)
        performance_json["gpu_metrics"][gpu_id] = {
            "name": gpu_data.get('name', 'Unknown GPU'),
            "energy": {},
            "compute": {},
            "memory": {},
            "communication": {},
            "other": {}  # For metrics not in predefined categories
        }
        
        # Categorize GPU metrics
        categorized_metrics = set()
        
        for section, metric_keys in gpu_sections.items():
            for metric_key in metric_keys:
                if metric_key in gpu_data:
                    performance_json["gpu_metrics"][gpu_id][section][metric_key] = extract_stat_dict(gpu_data[metric_key])
                    categorized_metrics.add(metric_key)
        
        # Add any remaining metrics to 'other' category
        for metric_key, metric_data in gpu_data.items():
            if metric_key not in categorized_metrics and metric_key != 'name':
                performance_json["gpu_metrics"][gpu_id]["other"][metric_key] = extract_stat_dict(metric_data)
    
    return performance_json
    


def _monitor_stats(additional_metrics,indices):
    """
    å†…éƒ¨å‡½æ•°ï¼šå¾ªç¯é‡‡é›†æ•°æ®ç›´åˆ° _monitor_running è¢«ç½®ä¸º False
    """
    while state._monitor_running:
        try:
            start_time = time.time()
            # ç”¨äºæ•°æ®æ’å…¥çš„æ—¶é—´æˆ³ï¼Œç²¾ç¡®åˆ°æ¯«ç§’
            time_stamp_insert = datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f')[:-5]
            # å¹¶è¡Œé‡‡é›†æ‰€æœ‰æŒ‡æ ‡
            
            # Update PSTL
            metrics = parallel_collect_metrics(additional_metrics,indices)
            # æ£€æŸ¥å¿…è¦æŒ‡æ ‡æ˜¯å¦é‡‡é›†æˆåŠŸ
            if metrics["gpu_info"] is None:
                print("æœªèƒ½é‡‡é›†åˆ°éƒ¨åˆ†æŒ‡æ ‡ï¼Œè·³è¿‡æœ¬æ¬¡é‡‡æ ·ã€‚")
                time.sleep(state._sampling_interval)
                continue

            # æ ¹æ®è¾“å‡ºæ ¼å¼è°ƒç”¨ä¿å­˜å‡½æ•°
            if state._output_format == "csv":
                save_to_csv(state._task_name, metrics, state._timestamp, time_stamp_insert)
            elif state._output_format == "mysql":
                save_to_mysql(state._task_name, metrics, state._timestamp, time_stamp_insert)
            else:
                print(f"æœªçŸ¥çš„è¾“å‡ºæ ¼å¼ï¼š{state._output_format}")
                break

            elapsed_time = time.time() - start_time
            state._execution_times['elapsed_time'].append(elapsed_time)

            remaining_time = max(0, state._sampling_interval - elapsed_time)
            time.sleep(remaining_time)
        except Exception as e:
            print(f"ç›‘æ§è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
            time.sleep(state._sampling_interval)


# @monitor_resources(
#     log_file="resource_monitor.log",
#     monitor_cpu=True,
#     monitor_mem=True,
#     monitor_disk=True,
#     disk_device="sda3"
# )
def start(task_name: str, sampling_interval: float = 1, output_format: str = "csv", additional_metrics: list = [], indices: list = [], position = (), cloud_region = None):
    """
    å¯åŠ¨ç›‘æ§ï¼šå¼€å§‹é‡‡é›†æ•°æ®
    :param task_name: ä»»åŠ¡åç§°ï¼Œç”¨äºæ ‡è¯†è®°å½•ï¼ˆåŒæ—¶ä½œä¸ºä¿å­˜æ•°æ®çš„æ–‡ä»¶/è¡¨åçš„ä¸€éƒ¨åˆ†ï¼‰
    :param sampling_interval: é‡‡æ ·æ—¶é—´é—´éš”ï¼ˆç§’ï¼‰
    :param output_format: è¾“å‡ºæ ¼å¼ï¼Œæ”¯æŒ 'csv' æˆ– 'mysql'
    :param additional_metrics: é¢å¤–çš„æŒ‡æ ‡åˆ—è¡¨ï¼Œæ”¯æŒ 'fp64_active', 'fp32_active', 'fp16_active''
    """
    if state._monitor_running:
        print(f"-----------------------------------------------------------------------------------------------------------------")
        print("ç›‘æ§å·¥å…·å·²ç»åœ¨è¿è¡Œã€‚")
        print(f"-----------------------------------------------------------------------------------------------------------------")
        return
    state._task_name = task_name
    state._sampling_interval = sampling_interval
    state._output_format = output_format.lower()
    state._timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    state._monitor_running = True
    state._monitor_thread = threading.Thread(target=_monitor_stats, args=(additional_metrics,indices,), daemon=True)
    state._monitor_thread.start()
    if cloud_region:
        state._cloud_region = cloud_region 
        state._position_use = 1
    # æ§åˆ¶å°è¾“å‡º
    print(f"-----------------------------------------------------------------------------------------------------------------")
    # print(f"ç›‘æ§å·¥å…·å·²å¯åŠ¨ï¼Œæ­£åœ¨ç›‘æ§ä»»åŠ¡ '{state._task_name}' ,é‡‡æ ·é—´éš”ä¸º {state._sampling_interval} ç§’ï¼Œè¾“å‡ºæ ¼å¼ä¸º '{state._output_format}'ã€‚")
    # print(f"ä»»åŠ¡ '{state._task_name}' è¿è¡Œç»“æŸåï¼Œç›‘æ§å·¥å…·å°†åœæ­¢è¿è¡Œã€‚")
    # å†™æˆè‹±æ–‡
    print(f"Monitoring tool started, monitoring task '{state._task_name}', sampling interval is {state._sampling_interval} seconds, output format is '{state._output_format}'.")
    print(f"After the task '{state._task_name}' ends, the monitoring tool will stop running.")
    print(f"-----------------------------------------------------------------------------------------------------------------")


def stop():
    """
    ç»“æŸç›‘æ§ï¼šåœæ­¢é‡‡é›†æ•°æ®
    """
    if not state._monitor_running:
        print(f"-----------------------------------------------------------------------------------------------------------------")
        print("ç›‘æ§å·¥å…·æ²¡æœ‰åœ¨è¿è¡Œã€‚")
        print(f"-----------------------------------------------------------------------------------------------------------------")
        return
    
    state._monitor_running = False
    state._monitor_thread.join()
    
    # Initialize performance metrics to return
    performance_metrics = None
    
    # ä»¥ä¸‹æ•´æ®µä¸ºè¾“å‡ºçš„ç®€ç•¥æ•°æ®
    if state._output_format == "csv":
        print(f"-----------------------------------------------------------------------------------------------------------------")
        # print(f"ä»»åŠ¡ '{state._task_name}' å·²ç»“æŸï¼Œç›‘æ§å·¥å…·åœæ­¢ï¼Œå…±é‡‡é›†{state._inserted_count}ä¸ªæ ·æœ¬ï¼Œè¯¦ç»†æ•°æ®å°†ä¿å­˜è‡³:{state._csv_file_path}ï¼Œç®€ç•¥æ•°æ®å¦‚ä¸‹ï¼š")
        # å†™æˆè‹±æ–‡
        print(f"Task '{state._task_name}' has ended, the monitoring tool has stopped, and {state._inserted_count} samples have been collected. Detailed data will be saved to: {state._csv_file_path}, and the summary data is as follows:")
        metrics = calculate_metrics(state._csv_file_path)
        if metrics: # ç¡®ä¿ metrics ä¸æ˜¯ç©ºçš„
            # print_formatted_metrics(metrics, state._task_name)
            performance_metrics = print_formatted_metrics(metrics, state._task_name)

    
    # TODO: Will be ignored, since I don't use SQL
    elif state._output_format == "mysql":
        print(f"-----------------------------------------------------------------------------------------------------------------")
        # print(f"ä»»åŠ¡ '{state._task_name}' å·²ç»“æŸï¼Œç›‘æ§å·¥å…·åœæ­¢ï¼Œå…±é‡‡é›†{state._inserted_count}ä¸ªæ ·æœ¬ï¼Œè¯¦ç»†æ•°æ®å°†ä¿å­˜è‡³:{state._table_name}ï¼Œç®€ç•¥æ•°æ®å¦‚ä¸‹ï¼š")
        # å†™æˆè‹±æ–‡
        print(f"Task '{state._task_name}' has ended, the monitoring tool has stopped, and {state._inserted_count} samples have been collected. Detailed data will be saved to: {state._table_name}, and the summary data is as follows:")
    
        metrics = calculate_metrics_from_mysql(state._table_name)
        if metrics: # ç¡®ä¿ metrics ä¸æ˜¯ç©ºçš„
            performance_metrics = print_formatted_metrics(metrics, state._task_name)
            
    # print(get_average_time('parallel_collect_metrics'))
    # print(get_max_time('parallel_collect_metrics'))
    # print(get_average_time('elapsed_time'))
    # print(get_max_time('elapsed_time'))
    state._inserted_count = -1 # ç”¨äºè®°å½•å·²æ’å…¥çš„è¡Œæ•°
    state._csv_file_path = "" # ç”¨äºè®°å½•CSVæ–‡ä»¶è·¯å¾„
    state._table_name = "" # ç”¨äºè®°å½•MYSQLçš„è¡¨æ ¼åç§°
    state._monitor_thread = None # ç”¨äºè®°å½•ç›‘æ§çº¿ç¨‹
    state._task_name = ""  # ç”¨äºè®°å½•ä»»åŠ¡åç§°
    state._sampling_interval = 10  # é‡‡æ ·é—´éš”
    state._output_format = "csv"  # è¾“å‡ºæ ¼å¼ï¼Œæ”¯æŒcsvå’Œmysql
    state._timestamp = ""  # ç”¨äºè®°å½•æ—¶é—´æˆ³
    state._execution_times = {} # ç”¨äºä¿å­˜æ¯ä¸ªå‡½æ•°çš„æ‰§è¡Œæ—¶é—´
    state._execution_times['elapsed_time'] = [] # ä¸“é—¨ç”¨äºè®°å½•é‡‡æ ·é¢‘ç‡çš„key-valueå¯¹
    state._position_use = 0 # ç”¨äºè®°å½•ä½ç½®ä½¿ç”¨æƒ…å†µ
    state._cloud_region = "Unknown_Region"
    
    return performance_metrics
